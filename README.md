# virtual-digital-human-project
virtual digital human project using Mediapipe and Unitychan
# Workflow
1. Real-time capture of facial landmarks  based on MediaPipe
2. Real-time Head Pose Estimation based on the facial landmarks
3. Facial expression recognition based on the facial landmarks
4. Real-time data transmission to virtual human model based on TCP 
5. Drive the virtual human model based on the transmission data

# References/ Credits

Detect 468 Face Landmarks in Real-time | OpenCV Python | 
|Project|Author|LICENSE|
|:-|:-:|-:|
|[VTuber-Python-Unity](https://github.com/mmmmmm44/VTuber-Python-Unity)|[mmmmmm44](https://github.com/mmmmmm44)|[LICENSE](https://github.com/mmmmmm44/VTuber-Python-Unity/blob/main/LICENSE)|
|[VTuber_Unity](https://github.com/kwea123/VTuber_Unity)|[AIè‘µ](https://github.com/kwea123)|[LICENSE](https://github.com/kwea123/VTuber_Unity/blob/master/LICENSE)|
|[Facial-emotion-recognition-using-mediapipe](https://github.com/REWTAO/Facial-emotion-recognition-using-mediapipe)|[ REWTAO ](https://github.com/REWTAO)|[LICENSE](https://github.com/REWTAO/Facial-emotion-recognition-using-mediapipe/blob/main/LICENSE)|
 
 
$$
\begin{aligned}
P(\text{disease}|\text{positive}) &= \frac{P(\text{positive}|\text{disease}) \cdot P(\text{disease})}{P(\text{positive})} \
&= \frac{0.99 \cdot 0.0001}{0.99 \cdot 0.0001 + 0.01 \cdot 0.9999} \
&= \frac{0.00099}{0.010098} \
&= 0.098
\end{aligned}
$$

# virtual-digital-human-project
virtual digital human project using Mediapipe and Unitychan
# Workflow
1. Real-time capture of facial landmarks  based on MediaPipe
2. Real-time Head Pose Estimation based on the facial landmarks
3. Facial expression recognition based on the facial landmarks
4. Real-time data transmission to virtual human model based on TCP 
5. Drive the virtual human model based on the transmission data

# References/ Credits

Detect 468 Face Landmarks in Real-time | OpenCV Python | 
|Project|Author|LICENSE|
|:-|:-:|-:|
|[VTuber-Python-Unity](https://github.com/mmmmmm44/VTuber-Python-Unity)|[mmmmmm44](https://github.com/mmmmmm44)|[LICENSE](https://github.com/mmmmmm44/VTuber-Python-Unity/blob/main/LICENSE)|
|[VTuber_Unity](https://github.com/kwea123/VTuber_Unity)|[AIè‘µ](https://github.com/kwea123)|[LICENSE](https://github.com/kwea123/VTuber_Unity/blob/master/LICENSE)|
|[Facial-emotion-recognition-using-mediapipe](https://github.com/REWTAO/Facial-emotion-recognition-using-mediapipe)|[ REWTAO ](https://github.com/REWTAO)|[LICENSE](https://github.com/REWTAO/Facial-emotion-recognition-using-mediapipe/blob/main/LICENSE)|
 
 
 
